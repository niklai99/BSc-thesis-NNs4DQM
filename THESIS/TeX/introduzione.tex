\chapter{Introduction}
% \addcontentsline{toc}{chapter}{Introduction} \markboth{INTRODUCTION}{}
\label{chap:Introduction}

% \section{Machine Learning applications in High Energy Physics}

Particle Physics, also known as High Energy Physics (HEP), is the branch of physics that studies the nature of the
particles that costitute matter and radiation. Its development can be located starting from the second half of the
$19^{\text{th}}$ century and, since then, theoretical physicists have been working on models that can accurately predict
and describe the outcome of experiments. The model that better describes the experimental results is the Standard Model
(SM), although it is common knowledge among the HEP community that SM is not complete. As a matter of fact, it does not
describe General Relativity in terms of quantum field theories, it does not give specifics about nautrino masses and
does not explain the existance of dark matter. These facts show that there are as yet undiscovered physical laws and
that our understanding of the world at its most fundamental level is lacking.\\

In order to interrogate experimental data in the search for New Physics (NP), scientists have come to realise that
employing a model-dependet approach (i.e. searching for specific NP models) has a critical disadvantage: a statistical
test which is designed to be sensitive to one specific hypothesis is typically insensitive to data departures of a
different nature from the one expected. This means that if new physics is present in the data, but not predicted by the
specific NP model that is being tested, it would not be discovered. A modern approach that overcomes the difficulties
underlined above is the so called model-indipendent approach. We define a certain approach "model-independent" if we are
not testing any specific physical model against our data. The main reason for which we demand a model-independent
approach is the advantage of sensitivity to a large variety of new physics scenarios.\\

In the realm of HEP, Machine Learning (ML) techniques has been used since early $2000$ (traditionally known as
Multivariate Analysis) in many crucial tasks, such as event classification, track reconstruction and particle
identification. In recent years, a Deep Learning algorithm has been developed in order to search for New Physics beyond
the Standard Model. Such algorithm outlines a model-indipendent approach by exploiting Neural Networks (NN) with multiple
hidden layers.\\

Although the above algorithm (which we will call the "NPL algorithm") looks promising in finding discrepancies, hidden
within our datasets, between collected data and SM predictions, the same approach can be taken to perform data quality
monitoring tasks. The main topic of this work is, in fact, the application of this Deep Learning algorithm to constantly
check whether the detector is collecting High Quality data (i.e. the detector is working as expected) or data
acquisition is compromised in some way. We would like to emphasize the importance of being able to accurately
discriminate High Quality (HQ) data from Low Quality (LQ) data: while the former is our gold mine, in which we hope to find
answers to the unresolved questions above, the latter is a complete waste of time. Lastly, we remind that our approach
to Data Quality Monitoring is model-indipendent, meaning that, in this field of application, we are not asked to make
assumptions on how data could be affected if the detector stops collecting HQ data, leading to a remarkable sensibility
to a large variety of LQ data acquisitions.



% \section{Data Quality Monitoring}




